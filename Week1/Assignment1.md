#ASSIGNMENT-1

##Part-1

1.	Difference between MLOps and AIOps

- AIOps involves overcoming difficulties and issues involving **IT Operations** whereas MLOps deals with simplification of **management, logistics and deployment** of machine learning models between the ml researchers and operations teams
- AIops works as *Continuous integration and deployment* for the core technology functions in learning and big data.
- AIOps automate the entire operations process across hybrid environments and create an accurate inventory for machines to correlate data points independently.  
- AIOps systems offers an automated AI system that can help reduce the number of issues that come to your operations teams. It does so by *analyzing past issues and resolutions* and attempts to *reduce the tasks and notifications*
- AIOps helps develope tools to help better **detect anomalies and errors** that your system may have never seen before
- AIOps is all about *supporting and reacting to its issues in real-time and providing analytics* to operations whereas MLOps is aboutfocuses on *managing, training and testing data* that is needed to create machine learning models effectively
- MLOps or AIOps both serve the same end purpose, i.e. **business automation**. While MLOps *bridges the gap between model building and deployment*, AIOps focuses on determining and reacting/solving to *issues in IT operations in real-time* so as to manage risks independently 

2.	The **linearity** of the learned relationship makes the interpretation in a linear regression model easy.

The biggest advantage of linear regression models is linearity. It makes the estimation procedure simple. Most importantly, these linear equations have an easy to understand interpretation on a modular level
Hence we conclude that *linear regression comes under interpretable machine learning models*

If the model is correct it meets the certain assumptions
- **linearity**-The linear regression model forces the prediction to be a linear combination of features. Linearity leads to interpretable models. 
- **normality**-The features follow a normal distribution
- **homoscedasticity**-
- **independence**-It is assumed that each instance is independent of any other instance
- **fixed features**-Input features are considered fixed. They are free of measurement errors
- **absence of multicollinearity**-We don't need correlated features. Where two features are strongly correlated, it becomes problematic to estimate the weights because the feature effects are additive and it becomes indeterminable to which of the correlated features to attribute the effects

**Interpretable Machine Learning** refers to methods and models that make the behavior and predictions of machine learning systems understandable to humans.

Linear regression model being an interpretable machine learning makes us know **why** a certain prediction is made.



It helps ease the curious minds and facilitates further learning.

**Algorithmic product recommendation** is an example.

The model itself becomes the *source of knowledge* instead of the data. Interpretability makes it possible to extract this additional knowledge captured by the model.

It will prove to be a highly **safe** model.

Interpretability is a useful *debugging tool for detecting bias* in Linear Regression models.

Explanations and interpreatbility helps **manage social interactions**.

It becomes easy to  **debug and audit** them when they can be interpreted.

##Part-2

![ml_ai](https://user-images.githubusercontent.com/48407607/127181670-7a41ec97-fb6a-4def-99da-1d1c0f75301e.png)



